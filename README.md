# ASSIP23_Youtube_ChatGPT_group_research

This is the research project that my team and I completed together for a summer 2023 internship program.
To further understand the project, please read the _Conference Poster_ file. Since this is a group project,
I cannot upload all the needed materials but just some parts of it to illustrate. 

Large language models (LLMs) like ChatGPT are, as per Frankfurt’s
definition, "bullshit" generators since they lack the ability to recognize
truths. As ChatGPT gains popularity, there is a growing concern that it
could facilitate the spread of “bullshits” (utterances made without
recognition of truths) on the Internet, exacerbating the media environment.
To understand this potential risk, we collected about 4,000 YouTube videos
related to ChatGPT that have been published since December 2022,
conducted qualitative analysis on approximately 400 randomly-sampled
videos, and examined the relationships between video features, bullshit
risk, and performance via sentiment analysis, ANOVA, and Fisher’s exact
test. We then leveraged channel statistics to train a machine learning
model that can predict the entire videos’ risk of bullshit. The study
emphasizes the high potential for AI-generated content to spread bullshit
and the necessity for social media designers to develop more effective
strategies that address the potential risk.
